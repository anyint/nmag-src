#!/bin/bash $NMAGBINDIR$/nsim-raw

import optparse,sys,types

import nbase
nbase._need_to_run_configure=False
nbase.conf.set('run_dir',".")

import nmesh

import logging
logging.getLogger('').setLevel(logging.INFO)
logging.getLogger('memory').setLevel(logging.INFO)

#silence ocaml's memory reports:
import ocaml
ocaml.nlog_setLogLevel('nmesh.ocaml',logging.WARN)
ocaml.nlog_setLogLevel('nfem.ocaml',logging.WARN)

##not used yet
#we store some data we have computed (to avoid computing it twice)
data= {}
data['wait_for_keypress_at_end']=False


def memory_report(tag):
    t,vmem,rss = ocaml.time_vmem_rss()
    logging.getLogger('memory').log(15,"Memory report: T=  %f VMEM=   %d KB RSS=   %d KB %s" % (t,int(vmem),int(rss),tag))

def histogram(a,bins,range=None,new=True):
    """wrapper around numpy.histogram to deal with the different versions of
    numpy.histogram.

    histogram.numpy returns (a,b) where a is the list of length n of the
    counts for each bin and b is
     in numpy version 1.0 and 1.1: a list of length n of the left bin edge and
     in numpy version 1.2 and above: a list of length n+1 with all the bin
     edges (i.e. including the right losing edge).

    Starting from version 1.1, a warning about this is printed, unless we use
    the extra parameter 'new=True' to switch to the new behaviour.

    However, numpy 1.0 will not know about the 'new' parameter: for this reason
    we need the if-statement below.

    (fangohr 30/07/2008)

    NOTE: the named argument 'new' disappeared in numpy version > 1.4.
    """
    
    import numpy
    v1,v2,v3 = map(int, numpy.__version__.split('.'))
    logging.log(15,'Using numpy version %s = %s' % (numpy.__version__,[v1,v2,v3]))
    if v1 == 1 and (v2 == 0 or v2 >= 4):
        ret = numpy.histogram(a,bins=bins,range=range)
        return ret 
    else:
        ret = numpy.histogram(a,bins=bins,range=range,new=new)
        return ret  

def parse_command_line(argvs):
    usage="usage: %prog [options] nmeshfile [outputfile]\n\n(C)"+\
           "University of Southampton, United Kingdom, 2005,2006.\n"+\
           "The NMESH PostProcessing (nmeshpp) tool."

    version="$Header$"

    parser = optparse.OptionParser(usage=usage,version=version)

    parser.add_option("--quality","-q",help="provide some data on the quality of the mesh",\
                      action="store_true",dest="quality")
    parser.add_option("--a0","-a",help="provide some data on the \
    variation of a0",action="store_true",dest="a0")

    parser.add_option("--histogram-bins",help="how many bins to use for histograms (default=%default)",\
                      dest="histogram_bins",metavar='bins',default=10,type='int')
    parser.add_option("--info","-i",help="display some data about the mesh",action="store_true",\
                      dest="info")

    parser.add_option("--vtk","-v",help="convert nmesh to vtk file",action="store_true",dest="vtk")

    scale_doc = """scale point positions by S. S can be (i) a scalar [all components of
point coordinates will be multiplied by that number] or (ii) a list
with length equal to the number of components of each point
coordinate. This allows, for example, to scale with 2 only in
z-direction using '--scale [1,1,2]'"""
    
    parser.add_option("--scale","-S",help=scale_doc,action="store",dest="scale",metavar="S")

    parser.add_option("--vtkquality","-Q",help="show bad simplices with mayavi",action="store_true",\
                      dest="vtkquality")

    parser.add_option("--vtkqualitymax",help="how many bad simplices to show (default=%default)",\
                      dest="vtkqualitymax",default=100,type='int',metavar='max')

    parser.add_option("--checkconsistency",help="check consistency of the mesh\
    (flying points or broken mesh)",action="store_true",dest="checkconsistency")

    parser.add_option("--magpar","-m",help="convert mesh to AVS file (extension should be .inp)",\
                      action="store_true",dest="magpar")

    parser.add_option("--vis-surfaces","-s",help="visualise surfaces of mesh using Visual Python",\
                      action="store_true",dest="vis_surfaces")

    parser.add_option("--connectivityplot",help="create file (png/eps/ps/svg) with connectivity \
    matrix. Filename needs to be specified. Fileformat is chosen from extension of filename.",\
                      action="store",dest="connectivityplot")

    parser.add_option("--reordernodes",help="Reorder nodes using parmetis to make connectivity \
    matrix more diagonal. (Not idempotent.) Need to provide name for reordered mesh file.",\
                      dest='reordernodes',action='store_true')
    
    parser.add_option("--loglevel","-l",metavar="level",help="verbosity level (stdout): \
    critical|error|warn|info|debug|INT.",dest='loglevel')

    parser.add_option("--data2files",metavar="filenamebase",help="Quality and edge length \
    analysis data will be saved in files",dest='data2filesbasename')

    parser.add_option("--refine","-r",metavar="level",help="Refine a given mesh according \
    to the given level; the refined mesh is built in a way that the edge of each simplex in\
    the coarse mesh is divided by the refinement level. The levels can be any integer>=2 \
    in 2D and only level=2 in 3D.",dest='refine')

    parser.add_option("--convert","-c",help="Convert input mesh file to output mesh file. Typically used to change from ASCII nmesh to hdf5 nmesh files. Use extension 'nmesh' for ascii and 'h5' for hdf5 files. HDF5 files are stored in compressed binary and therefore smaller.",action="store_true",dest="convert")

    parser.add_option("--partitioning",help="create vtk file that shows how the nodes are distributed over cpus. If NP is int, equal distribution of nodes. if NP is list of ints, then the cpu0 takes all nodes from index 0 to the first entry of thelist, cpu1 takes all indices from first list entry to second list entry, etc. Need to provide filename for output file. ", action="store",metavar="NP",dest="partitioning_np")

    distort_doc = """distort the mesh by adding a random displacement to the y-coordinates (by default) of all nodes at the front and rear of the mesh and stretching the intermediate parts accordingly. This can be used to simulate edge roughness in a nanowire, for example. The amount of displacement for each node is chosen at random from a normal distribution with mean 0 and standard deviation D (thus D determines the 'amplitude' of the resulting roughness). It is a function of the x-coordinate of the node only, i.e., all nodes with the same z-coordinate are shifted in y-direction by the same amount. The correlation in the displacement of adjacent nodes can be controlled using --correlation-length (for details see the nmag manual). The value of D can be a single number or a list of numbers (e.g., D=\"[0.1,0.2,0.3]\"). In the latter case multiple output files are created, each distorted with one value of D in the list (the filenames are based on the output filename provided on the command line, appended with the individual values of D). Note that when providing a list of values for D, the same randomization seed is used for all distortions (i.e., the 'shape' of the distortion will be the same, only the amplitude will vary)."""
    parser.add_option("--distort","-d",help=distort_doc,action="store",dest="distort",metavar="D")

    parser.add_option("--correlation-length",help="set correlation length for mesh distortion",\
                      action="store",dest="correlation_length",default=None,metavar="C")

    parser.add_option("--distort-along-axis",help="axis along which the distortion unfolds (default: X)",\
                      action="store",dest="distort_along_axis",default="X",metavar="[X|Y|Z]")

    parser.add_option("--front-rear-axis",help="during mesh distortion, consider those sides of the mesh as 'front' and 'rear' that are orthogonal to this axis (default: Y). Accordingly, this is also the direction in which the surface nodes are shifted.",\
                      action="store",dest="front_rear_axis",default="Y",metavar="[X|Y|Z]")

    parser.add_option("--seed",help="seed the random number generator with S before distorting the mesh.",\
                      action="store",type="int",dest="distort_seed",default=None,metavar="S")

    (options, arguments) = parser.parse_args(argvs)

    return options,arguments



def do_create_vtk_file(mesh,options,outfile):
    
    logging.info("Convert lists into vtkdata structure")
	
    vtkdata = nmesh.visual.mesh2vtk(mesh.tolists(),VTKonly=True,body_numbers=True,node_numbers=True)

    logging.info("Writing data to '%s'" % outfile)
    nmesh.visual.save_vtk(vtkdata, outfile,format='binary',directory='.')


def do_vis_surfaces(mesh,options,radius=0.01):
    try:
        import visual
    except ImportError,msg:
        logging.critical("Need Visual Python for --vis-surface")
        logging.critical("(http://www.vpython.org/)")
        logging.critical("Exception is ImportError, %s" % msg)
        raise ImportError,msg

    visual_objects = []
    x = mesh.points

    #this only makes sense for 3d meshes:
    if 1 >= mesh.dim or mesh.dim >=4:
        raise ValueError,"--vis-surface can only deal with meshes in 3d and 2d"

    if mesh.dim == 3:
        for surface in mesh.surfaces:
            link1 = surface[0:2]
            link2 = surface[1:3]
            link3 = [surface[2],surface[0]]

            links = [link1,link2,link3]

            for link in links:
                point1 = visual.vector(x[link[0]])
                point2 = visual.vector(x[link[1]])
                axis=point2-point1
                pos=point1

                visual_objects.append(visual.cylinder(pos=pos, axis=axis, radius=radius))
    elif mesh.dim == 2:
        for surface in mesh.surfaces:
            link = surface
            point1 = visual.vector(x[link[0]])
            point2 = visual.vector(x[link[1]])
            axis=point2-point1
            pos=point1

            visual_objects.append(visual.cylinder(pos=pos, axis=axis, radius=radius))
        
    data['wait_for_keypress_at_end']=True


def do_create_magpar_file(mesh,options,outfile):
    logging.info("Writing data to '%s'" % outfile)
    nmesh.export.magpar_ucd(mesh, outfile)

def _nr_simplices(mesh):
    return len( mesh.simplices )

def _nr_surfaces(mesh):
    return len( mesh.surfaces )

def _nr_points(mesh):
    return len( mesh.points )


##working but not used
#def _unique_list( a ):
#    d={}
#    for elem in a:
#        d[elem]=None
#    keys = d.keys()
#    keys.sort()
#    return keys

def do_info(mesh):
    def _unique_points( a ):
        import types
        d={}
        for elem in a:
            if type(elem)==types.ListType:
                for elem2 in elem:
                    d[elem2]=None
            else:
                d[elem]=None
        keys = d.keys()
        keys.sort()
        return keys
        
    dim = mesh.dim
    print "====== Info output: ========================================================"
    print "%5d-dimensional mesh" % dim
    nr_simplices = _nr_simplices(mesh)
    memory_report("-")
    print "%5d volume elements (%dd)" % (nr_simplices,dim)
    memory_report("-")
    nr_surfaces = _nr_surfaces(mesh)
    print "%5d surface elements (%dd)" % (nr_surfaces,dim-1)
    memory_report("-")
    nr_points = _nr_points(mesh)
    print "%5d points" % nr_points
    memory_report("-")
    
    print "%5d simplex regions (%s)" % (len(_unique_points(mesh.simplicesregions)),str(_unique_points(mesh.simplicesregions)))
    memory_report("-")

    print "%5d point regions (%s)" % (len(_unique_points(mesh.pointsregions)),str(_unique_points(mesh.pointsregions)))
    memory_report("-")

    print "%5d region volumes (%s)" % (len(mesh.regionvolumes),str(mesh.regionvolumes))
    memory_report("-")

    nr_boundary_points =  len(filter( lambda x : len(x)==2,mesh.pointsregions))   
    bem_size = round(nr_boundary_points**2 *8 / 1024./1024.)

    print "%5d boundary points (-> BEM size<=%5.0dMB)" \
          % (nr_boundary_points, bem_size)

    total_periodic_points = sum(map(len,mesh.periodicpointindices))
    periodic_points = len(mesh.periodicpointindices)
    mirage_points = total_periodic_points-periodic_points

    print "%5d periodic points (mirage=%d, total=%d)" % (periodic_points,
    	       		       		   	         mirage_points,
							 total_periodic_points)


    #work out raw memory requirements for this mesh
    floatsize = 8
    intsize = 4
    mem_points = dim*nr_points*floatsize
    mem_surfaces = dim*nr_surfaces*intsize
    mem_simplices = (dim+1)*nr_simplices*intsize
    mem_volregion = 1*nr_simplices*intsize
    mem_pointregion = 1*nr_points*intsize
    mem_mesh = mem_points+mem_surfaces+mem_simplices+mem_volregion+mem_pointregion

    logging.getLogger('').log(15,
                              "Minimum memory requirements of this mesh: %.2f MB" \
                              % (float(mem_mesh)/1024./1024.))

    try:
        import numpy
        a0s=_compute_a0_mod( mesh )
        print "a0: average=%f, std=%f, min=%f, max=%f" % (numpy.average(a0s),
                                                          numpy.std(a0s),a0s.min(),a0s.max())
    except ImportError:
        pass

def _star_plot(value,range,maxstars,char='*'):
    """Given a value, a range=(min,max) of values, and the maximum number of stars requested
    (for value==max), this function returns a string consisting out of stars to represent 'value'.

    Note: to emphasise any values >0, we will always round up."""
    stars = float(value)/(range[1]-range[0])*maxstars
    return int(stars+1-1e-8)*char

def _compute_a0_mod( mesh ):
    if data.has_key('a0'):
        return data['a0']
    else:
        import numpy
        links = numpy.array(mesh.links)
        assert len(links)>0,"Need at least one link (=2 points)"
        points= numpy.array(mesh.points)
        linkvectors = numpy.take(points,links[:,1],axis=0)-numpy.take(points,links[:,0],axis=0)

        a0_mod_vec=numpy.sqrt(numpy.sum(linkvectors**2,axis=1))
        data['a0']=a0_mod_vec
    return data['a0']

def do_a0(mesh,options):
    import numpy
    a0s = _compute_a0_mod( mesh )
    count_a0, bins = histogram(a0s,bins=options.histogram_bins)

    if options.data2filesbasename:
        f=open(options.data2filesbasename+'.a0','w')
        for bin,value in zip(bins,count_a0):
            f.write('%f %d\n' % (bin,value))
        f.close()

      
    probability_a0 = count_a0 / float(len(a0s))
    
    print "====== a0 output: ==========================================================="
    #Outpu data:
    dbin = bins[1]-bins[0]
    print "[a0   interval] counts = probability"
    for i in range(len(count_a0)):
        lbin=bins[i]
        print "[% 6.3f-%6.3f] %6d =%5.2f%% %s" % (lbin,lbin+dbin,count_a0[i],probability_a0[i]*100,
                                                  _star_plot(probability_a0[i],(0,probability_a0.max()),40))

    print
    print "average   a0: <a0>   = %f" % (numpy.average(a0s))
    print "stand dev a0: <a0^2> = %f^2" % (numpy.std(a0s))
    print "min and max :        =(%f,%f)" % (a0s.min(),a0s.max())

def do_quality(mesh,options):
    #This is the volume element meshinfo structure in meshinfo[2][2]:
    #'Simplex info (points-coords,((circumcirc center,cc radius),(ic center,ic radius),region))

    #And here is one example (2d mesh):
    #([51, 61, 62],
    # ([3.0407746222387044, 1.7944092331307016], 0.21872919737937571),
    # ([3.0943442752565029, 1.8555501724490762], 0.094259340076866718),
    # 2)

    #find number of dimensions, simplices and surfaces simplices
    dim = mesh.dim
    nr_vol_simplices = _nr_simplices(mesh)
    nr_sur_simplices  = _nr_surfaces(mesh)

    try:
        import numpy
    except ImportError,msg:
        print "Need numpy to compute histograms."
        raise ImportError,msg
    from numpy import array

    #work out volume element histogram
    ic_radii_vol=array(map(lambda a : a[2][1], mesh.tolists()[2][2]))
    cc_radii_vol=array(map(lambda a : a[1][1], mesh.tolists()[2][2]))
    quality_vol = ic_radii_vol/cc_radii_vol*dim

    counts_vol,leftbinedges = histogram(quality_vol,range=(0,1),bins=options.histogram_bins)

    if options.data2filesbasename:
        f=open(options.data2filesbasename+'.quality','w')
        for bin,value in zip(leftbinedges,counts_vol):
            f.write('%f %d\n' % (bin,value))
        f.close()
    
    #from IPython.Shell import IPShellEmbed

    #ipshell = IPShellEmbed()

    #ipshell() # this call anywhere in your program will start IPython


    
    probability_vol = counts_vol/float(nr_vol_simplices)

    if False: #surface element quality data is not yet provided by nmesh.tolists()
        ic_radii_sur=array(map(lambda a : a[2][1], mesh.tolists()[4][2]))
        cc_radii_sur=array(map(lambda a : a[1][1], mesh.tolists()[4][2]))
        quality_sur = ic_radii_sur/cc_radii_sur*(dim-1)
        counts_sur,leftbinedges = histogram(quality_sur,range=(0,1),bins=options.histogram_bins)
        probability_sur = counts_sur/float(nr_sur_simplices)

    #output data:
    dbin = 1.0/options.histogram_bins
    print "====== Quality output: ======================================================"

    print "[qual interval] counts = probability"

    for i in range(len(counts_vol)): 
        lbin=leftbinedges[i]
        print "[% 6.3f-%6.3f] %6d =%5.2f%% %s" % (lbin,lbin+dbin,counts_vol[i],probability_vol[i]*100,
                                                  _star_plot(probability_vol[i],(0,probability_vol.max()),40))

def do_vtkquality(mesh,options):

    print "====== VTKQUALITY: =========================================================="
    print "WARNING: This has been hacked together without much thought (fangohr 26/09/2006 23:29)"
    print "   We call mayavi directly; this may not be a good choice. Or it may be. Time will"
    print "   have to tell. In any case, don't rely on this feature in scripts for now!"
    
    # now order the mesh by it's quality and display the worst options.vtkqualitymax elements only
    vtkData, points, simplices, simplexIndices, icradii, ccradii = nmesh.visual.mesh2vtk(mesh.tolists(), VTKonly=False)

    # calculate the quality metric
    in2circ = nmesh.visual.findRatios(icradii, ccradii, factor=mesh.dim)

    meshinfo = mesh.tolists()

    # order the mesh by this metric
    meshinfo = nmesh.visual.order_mesh(meshinfo, data=in2circ)
    #meshinfo = nmesh.visual.order_mesh(meshinfo, axis = 2)

    import mayavi
    v= mayavi.mayavi()

    # display this information and open the ExtractUnstructuredGrid filter
    nmesh.visual.solid_in2circ(meshinfo, myv = v)
    #v = nmesh.visual.show_bodies_mayavi(mesh)

    f = v.load_filter('ExtractUnstructuredGrid',0)

    # set the cellMin and cellMax appropriately and then display the filter
    # configuration dialog box for the user
    f.fil.SetCellClipping(1)
    f.fil.SetCellMaximum(options.vtkqualitymax)
    f.fil.SetCellMinimum(0)
    f.renwin.Render()

    # superimpose a wireframe to show the outline of the solid
    dvm = v.get_current_dvm()
    mm2 = dvm.add_module_mgr_gui()        # add a new module_manager
    outline = v.load_module('SurfaceMap',0)
    outline.mapper.SetScalarVisibility(0)
    outline.actor.GetProperty().SetRepresentationToWireframe()
    outline.renwin.Render()

    # load dialog box
    f.configure()

    data['wait_for_keypress_at_end']=True


def do_scale_coordinates(mesh,options,outfile,scalevector):

    logging.debug("scale vector is %s" % str(scalevector))
    
    points = mesh.points

    assert len(points[0])==len(scalevector)

    for i in range(len(points)):
        points[i] = map( lambda a,b: a*b, points[i],scalevector)

    logging.debug("Creating new mesh instance with  modified coordinates")
    mesh = nmesh.mesh_from_points_and_simplices(points,mesh.simplices,mesh.simplicesregions)
    logging.info("Saving mesh with modified coordinates to '%s'" % outfile)
    mesh.save(outfile)
    return None


def do_distort_mesh_1D(mesh, options, outfile, distort_factors, correlation_length, distort_along_axis, front_rear_axis):
    import numpy, scipy.interpolate, math, re

    points = mesh.points
    surfaces = mesh.surfaces
    eps = 1e-6

    assert len(points[0])==3
    logging.debug("distort factor is %s" % distort_factors)

    # TODO: Maybe allow arbitrary axes (not just coordinate directions)?
    if front_rear_axis == 2:
        X=0; Y=1; Z=2
    elif front_rear_axis == 1:
        X=2; Y=0; Z=1
    elif front_rear_axis == 0:
        X=1; Y=2; Z=0
    else:
        raise IndexError("Axis must be in the range 0..2")

    # Compute min and max coordinates along the specified axis
    ptcoords = sorted(list(set(map(lambda p: p[distort_along_axis], points))))
    numpts = len(ptcoords)
    xmin_global = min(ptcoords)
    xmax_global = max(ptcoords)

    # Build a hash table with x-values as keys and the indices of
    # surface triangles that lie 'above' these x-positions as values.
    h = {} 
    for x in ptcoords:
        h[x] = []
    for i in xrange(len(surfaces)):
        s = surfaces[i]
        xmin = min(points[s[0]][distort_along_axis], points[s[1]][distort_along_axis], points[s[2]][distort_along_axis])
        xmax = max(points[s[0]][distort_along_axis], points[s[1]][distort_along_axis], points[s[2]][distort_along_axis])
        for x in ptcoords:
            if x > xmax:
                break
            if x >= xmin:
                h[x].append(i)
    for k in h.keys():
        h[k] = list(set(h[k]))

    def same_half_plane(A,B,C,P):
        # returns true if C and P lie on the same side of the line AB
        # (after projecting all points into the plane orthogonal to front_rear_axis)
        n = numpy.array([A[Y]-B[Y], B[X]-A[X]])
        v = numpy.array([P[X]-A[X], P[Y]-A[Y]])
        w = numpy.array([C[X]-A[X], C[Y]-A[Y]])

        if numpy.sign(numpy.dot(v,n)) == numpy.sign(numpy.dot(w,n)):
            return True
        elif math.fabs(numpy.dot(v,n)) < eps:
            # We assume an intersection because P lies very close to the triangle ABC
            return True
        else:
            return False
    
    def triangle_intersects(A, B, C, P):
        return same_half_plane(A,B,C,P) and same_half_plane(B,C,A,P) and same_half_plane(C,A,B,P)

    def is_degenerate(s):
        A = numpy.array(points[s[0]])
        B = numpy.array(points[s[1]])
        C = numpy.array(points[s[2]])
        v = B-A
        w = C-A
        return math.fabs(v[X]*w[Y]-v[Y]*w[X]) < eps

    def get_possibly_intersecting_surfaces(P):
        x = P[distort_along_axis]
        return h[x]

    def find_intersecting_surfaces(P):
        S = []
        for i in h[P[distort_along_axis]]:  # iterate over all possibly intersecting surfaces
            s = surfaces[i]
            if is_degenerate(s):
                # TODO: This test should be superfluous now that we have the hash table h.
                #       Hmm, noooooo!?!
                # Hmm, we should think about whether we should include degenerate triangles
                # for more general axis directions (they may be needed).
                continue
            if triangle_intersects(points[s[0]], points[s[1]], points[s[2]], P):
                #print "   surface %s intersects!" % s
                S.append(s)
        return S

    def find_intersecting_surface_point(S, P):
        A = numpy.array(points[S[0]])
        B = numpy.array(points[S[1]])
        C = numpy.array(points[S[2]])
        n = numpy.cross(B-A, C-A)

        if front_rear_axis == 0:
            z = -((P[1]-A[1])*n[1] + (P[2]-A[2])*n[2]) / n[0] + A[0]
            return [z, P[1], P[2]]
        elif front_rear_axis == 1:
            z = -((P[2]-A[2])*n[2] + (P[0]-A[0])*n[0]) / n[1] + A[1]
            return [P[0], z, P[2]]
        elif front_rear_axis == 2:
            z = -((P[0]-A[0])*n[0] + (P[1]-A[1])*n[1]) / n[2] + A[2]
            return [P[0], P[1], z]
        else:
            raise IndexError("front_rear_axis must be one of 0, 1, 2")

    # Given a point P, find all surface triangles of the mesh that
    # intersect with a line through P in the direction of axis. The two
    # extremal intersection points along this axis are returned (as numpy
    # arrays).
    def find_extremal_intersecting_surface_points(P):
        slist = find_intersecting_surfaces(P)
        if slist == []:
            raise Exception("Could not find any intersecting surfaces for point P=%s"%P)
        if len(slist) == 1:
            raise Exception("Could only find a single intersecting surface for point P=%s (there should be at least two)"%P)

        plist = map(lambda S: find_intersecting_surface_point(S, P), slist)
        P1 = max(plist, key=lambda P: P[front_rear_axis])
        P2 = min(plist, key=lambda P: P[front_rear_axis])
        return numpy.array(P1), numpy.array(P2)

    def interpolate_coordinate(x, a, b, c, d):
        if math.fabs(d-c) < eps:
            print "Interpolated interval is empty: c=%s, d=%s" % (c,d)
        return (x-a)/float(b-a) * (d-c) + c

    # Create two random deviations along the direction of distort_along_axis
    # and interpolate each of them with a spline function.
    xx = numpy.concatenate((numpy.arange(0.5*(xmin_global+xmax_global) - 0.5*correlation_length, xmin_global, -correlation_length)[::-1],
                            numpy.arange(0.5*(xmin_global+xmax_global) + 0.5*correlation_length, xmax_global,  correlation_length)))
    if xx[0] != xmin_global:
        xx = numpy.concatenate(([xmin_global], xx))
    if xx[-1] != xmax_global:
        xx = numpy.concatenate((xx, [xmax_global]))

    numpy.random.seed(options.distort_seed)
    yy1 = numpy.random.normal(size=len(xx))
    yy2 = numpy.random.normal(size=len(xx))
    sp1 = scipy.interpolate.InterpolatedUnivariateSpline(xx,yy1)
    sp2 = scipy.interpolate.InterpolatedUnivariateSpline(xx,yy2)

    # ## For debugging: plot the random distortion functions
    # import pylab
    # xxfine = numpy.linspace(xmin_global, xmax_global, 500)
    # #pylab.plot(xx, yy1, 'b')
    # #pylab.plot(xx, yy2, 'r')
    # pylab.plot(xxfine, map(sp1, xxfine), 'b')
    # pylab.plot(xxfine, map(sp2, xxfine), 'r')
    # pylab.show()

    # For each distortion factor, newpoints will contain an array with
    # the corresponding distorted mesh.
    newpoints = {}
    for d in distort_factors:
        if float(d) == 0.0:
            # Simply copy the list of points because no work needs to be done
            newpoints[d] = list(points)
        else:
            newpoints[d] = []

    numpts = len(points)
    if set([0.0]) != set([float(d) for d in distort_factors]):
        # We only need to distort the mesh if any of the distortion factors is non-zero
        for i in xrange(len(points)):
            if i % 1000 == 0:
                print "Point %s of %s" % (i, numpts)

            P = points[i]
            Q1,Q2 = find_extremal_intersecting_surface_points(points[i])
            for d in distort_factors:
                dd = float(d) # distort_factors contains string representations of the numbers,
                              # hence we need to convert them to floats first
                if dd == 0.0:
                    continue
                R = P[:]
                if dd != 0:
                    w1 = Q1[front_rear_axis] + dd*sp1(Q1[distort_along_axis])
                    w2 = Q2[front_rear_axis] + dd*sp2(Q2[distort_along_axis])
                    R[front_rear_axis] = interpolate_coordinate(R[front_rear_axis], Q1[front_rear_axis], Q2[front_rear_axis], w1, w2)
                newpoints[d].append(R)

    outfile = re.sub("\.nmesh$", "", outfile)  # strip suffix .nmesh from outfile (if present)

    for d in distort_factors:
        logging.debug("Creating new mesh instance for distortion factor %s" % d)
        mesh = nmesh.mesh_from_points_and_simplices(newpoints[d], mesh.simplices, mesh.simplicesregions)
        suffix = ""
        if len(distort_factors) > 1:
            suffix = "-%s"%d
        mesh.save("%s%s.nmesh" % (outfile,suffix))
        logging.info("Saved mesh with modified coordinates to '%s%s.nmesh'" % (outfile,suffix))
    return None
    


def do_checkconsistency(mesh):

    dim = mesh.dim
    check_mesh = []

    def retrieve_check(pos):
        if check_mesh[pos]:
            return "ok"
        else:
            return "ko" 

    def extract_pts_from_surface(surface):
        surf = surface[0]
        surf.sort()
        return surf

    def extract_pts_from_simplex(simplex):
        sx = simplex[0]
        sx.sort() 
        return sx

    # Check that each point belongs at least
    # to one of the simplices

    logging.info( "checking points ...")
    points_in_simplices = []

    meshinfo = mesh.tolists()
    
    for sx_ix in range(_nr_simplices(mesh)): 
        sx = meshinfo[2][2][sx_ix]
        for pt_ix in sx:
            if pt_ix not in points_in_simplices:
               points_in_simplices.append(pt_ix)

    check_mesh.append(len( points_in_simplices) != _nr_points(mesh))

    # Check that each (N-1)-dim simplex belonging to
    # a N-dim simplex have a partner (each face is shared
    # by two simplices or it is on the boundary)

    logging.info("checking mesh ...")
    faces = []
    simplices = map(extract_pts_from_simplex,meshinfo[2][2])
    for sx in simplices:
        for i in range(dim+1):
            face = sx[:i] + sx[(i+1):]
            faces.append(face)

    faces.sort()
    surfaces = map(extract_pts_from_surface,meshinfo[4][2])

    single_face = []
    for face in (faces):
        if faces.count(face) != 2:
            single_face.append(face)

    check_mesh.append(True)
    for face in (single_face):
        if surfaces.count(face) == 0:
            check_mesh[1] = False
        
    print "====== Check consistency output: ====================================================="
    print "Mesh points: %s" % (retrieve_check(0))
    print "Mesh consistency: %s" % (retrieve_check(1))




def do_refine(mesh,options,outfile):
    logging.info("About to refine mesh")	
    
    coarse_mesh=mesh.raw_mesh
    level = int(options.refine)
    if level<2:
        raise ValueError,"The level must be >= 2 for a 2D mesh and 2 for a 3D mesh."
    if mesh.dim	== 2:
        (fine_mesh,coarse_fine_info)=ocaml.finer_mesh_from_coarse_mesh(level,coarse_mesh)
    elif mesh.dim == 3:
	if level != 2:
            raise ValueError,"The level must be 2 for a 3D mesh."
        else: 
            (fine_mesh,coarse_fine_info)=ocaml.finer_mesh_from_coarse_mesh(int(options.refine),coarse_mesh)

    logging.info("Saving refined mesh to '%s' (warning: is text-based mesh format)" % outfile)
    #(fangohr 28/03/2007): just note that we cannot save h5 file 
    #meshes here. Need to wrap up ocaml mesh into python mesh
    #and then use 'mesh.save()'. 
    #Refined meshes tend to be large, so writing them compressed is 
    #important.
    ocaml.mesh_writefile(outfile,fine_mesh)


def do_connectivityplot(mesh,options,filename):
    import pylab
    import numpy
    import os
    fileformats = ['png','eps','ps','svg']
    filenameext = os.path.basename(filename).split('.')[-1]
    if filenameext in fileformats:
        pass #all is well
    else:
        logging.warn("Connectivity plot: Don't know fileformat '%s' (extension of '%s') -- will save as png." % (filenameext,filename))
        filename=filename+'.png'
    n=len(mesh.points)
    c = numpy.zeros(shape=(n,n), dtype=numpy.bool)
    for (i,j) in mesh.links:
        c[i,j]=True
        c[j,i]=True
    pylab.matshow(c,cmap=pylab.cm.gray)
    pylab.savefig(filename)


def do_partitioning_np(mesh,np,outfile):

    def smaller_than_listentry_index(item,list_):
        assert len(list_) > 0, "Need non-empty input list"
        if item < list_[0]:
            return 0
        for i in range(1,len(list_)):
            if list_[i-1] <= item < list_[i]:
                return i
        return len(list_)
        
            

    #number of points
    n = len(mesh.points)

    pdata = []
    if type(np) == types.IntType:

        #now split for np processors:
        import math
        ni = int(math.ceil( float(n) / np ))
        nlast = n - ni*(np-1)

        logging.info("Using %d cpus with %d points on cpus 0 to %d, and %d points on cpu %d."\
                  % (np,ni,np-1-1,nlast,np))

        assert nlast <= ni,"Something wrong with calculation of node distribution"


        for i in range(np-1):
            data_value = 1.0*i
            pdata.extend( [data_value] * ni )
            logging.info("%d nodes on processor %d" % (ni,i))
        pdata.extend( [1.0*(np-1)] * nlast )
        logging.info("%d nodes on processor %d" % (nlast,np-1))

        assert len(pdata) == n,"Internal error, len(pdata)=%d, but n=%d" % \
               (len(pdata),n)

    elif type(np) == types.ListType:
        #for i in range(n):
        #    pdata.append(smaller_than_listentry_index(i,np))
	for cpu_id in range(len(np)):
	    for i in range(np[cpu_id]):
		pdata.append(cpu_id)

	assert len(pdata)==n,"Number of nodes in mesh=%d and number of nodes in partition=%d disagree" % (n,len(pdata))
    else:
        raise NotImplementedError,"Can only deal with int or list of ints"
        
    import nfem.visual
    vtk = nfem.visual._vtk_createVtkData(mesh.points,mesh.simplices,pdata,'cpu_id <>')
    vtk.tofile(outfile,format='ascii')

    #from IPython.Shell import IPShellEmbed
    #ipshell = IPShellEmbed([])
    #ipshell() # this call anywhere in your program will start IPython
    logging.info("Written partitioning data into '%s'." % outfile)


#main program
options,arguments = parse_command_line(sys.argv)

if options.loglevel:
    logging.getLogger('').setLevel(nbase.loglevel_int_of_string(options.loglevel))

logging.debug("Options   are: '%s'" % str(options))
logging.debug("Arguments are: '%s'" % str(arguments))

outfile = None
outfile_feature = None

if len(arguments) == 0:
    raise ValueError,"Don't know what this means (expect at least one arguments which is the program name)"
elif len(arguments) == 1:
    raise ValueError,"Need filename of nmesh file to process (use '-h' for help)"
elif len(arguments) in [2,3]:
    infile = arguments[1]
    logging.debug("input file name is '%s'" % infile)

if len(arguments) == 3:
    outfile = arguments[2]
    logging.debug("output file name is '%s'" % outfile)
    
if len(arguments) >= 4:
    print "Arguments are:",arguments
    print "Options   are:",options
    raise ValueError,"It appears you are passing more arguments than I can handle."

#check whether we need to reorder the mesh
if options.reordernodes:
    do_reorder = True
    logging.info("Will reorder mesh when reading (using parmetis)")
else:
    do_reorder = False


#now process any requests
def check_and_tag_outfile(feature):
    global outfile,outfile_feature
    if outfile==None:
        raise ValueError,"No output file name has been provided (for feature '%s')." % feature
    if outfile_feature:
        raise ValueError,"Outfile is used already for feature '%s'" % outfile_feature
    outfile_feature = feature
    logging.debug("Will use outfile='%s' for feature '%s'" % (outfile,outfile_feature))

logging.info("Reading data from nmesh file '%s'" % infile)
mesh = nmesh.load(infile,reorder=do_reorder)

if options.vtk:
    check_and_tag_outfile('--vtk')
    do_create_vtk_file(mesh,options,outfile)


if options.magpar:
    check_and_tag_outfile('--magpar')
    if outfile[-4:] != '.inp':
        logging.warn("Mesh file for magpar should end with extension '.inp'")
    do_create_magpar_file(mesh,options,outfile)

if options.scale:
    check_and_tag_outfile('--scale')
    a=eval(options.scale)
    if type(a) in [types.FloatType,types.IntType]:
        scalevec = [a]*mesh.dim

    elif type(a) in [types.ListType]:
        #got list
        if len(a) != mesh.dim:
            msg = "Scale factor is '%s', i.e. %d dimensional but mesh is %d dimensional.\n" % (options.scale,len(a),mesh.dim)
            msg += "Scale factor needs to be (i) a scalar or (ii) a list with length == mesh.dim"      
            raise ValueError, msg
        scalevec = a
        
    do_scale_coordinates(mesh,options,outfile,scalevec)

if options.distort:
    import ast
    check_and_tag_outfile('--distort')

    # Convert the distortion factor(s) provided at the command line
    # into a list of strings representing these values (we want a list
    # of strings because we need to avoid rounding issues at this
    # point since the output file names should be based exactly on the
    # command line arguments given).
    if isinstance(ast.literal_eval(options.distort.lstrip()), (list,tuple)):
        distort_factors = options.distort.lstrip(' ([').rstrip(' ])').split(',')
    else:
        distort_factors = [options.distort]
    for i in xrange(len(distort_factors)):
        distort_factors[i] = distort_factors[i].lstrip().rstrip()

    if options.correlation_length:
        correlation_length = eval(options.correlation_length)
    else:
        raise StandardError("No correlation length specified for mesh distortion.")

    if len(distort_factors) > 1 and not options.distort_seed:
        raise StandardError("When using multiple distortion factors a seed must be specified using --seed")

    if options.distort_along_axis == "X":
        distort_along_axis = 0
    elif options.distort_along_axis == "Y":
        distort_along_axis = 1
    elif options.distort_along_axis == "Z":
        distort_along_axis = 2

    if options.front_rear_axis == "X":
        front_rear_axis = 0
    elif options.front_rear_axis == "Y":
        front_rear_axis = 1
    elif options.front_rear_axis == "Z":
        front_rear_axis = 2

    do_distort_mesh_1D(mesh, options, outfile, distort_factors, correlation_length, distort_along_axis, front_rear_axis)


if options.refine:
    check_and_tag_outfile('--refine')
    do_refine(mesh,options,outfile)

if options.info:
    do_info(mesh)

   
if options.quality:
    do_quality(mesh,options)

if options.connectivityplot:
    do_connectivityplot(mesh,options,options.connectivityplot)

if options.a0:
    do_a0(mesh,options)

if options.vtkquality:
    do_vtkquality(mesh,options)

if options.checkconsistency:
    do_checkconsistency(mesh)

if options.vis_surfaces:
    do_vis_surfaces(mesh,options)

if data['wait_for_keypress_at_end']:
    raw_input("Press return to continue")

if options.reordernodes:
    check_and_tag_outfile("--reordernodes")
    logging.info("Writing re-orderd mesh to '%s'." % outfile)
    mesh.save(outfile)

if options.convert:
    check_and_tag_outfile("--convert")
    logging.info("Writing mesh to '%s'." % outfile)
    mesh.save(outfile)

if options.partitioning_np:
    np = options.partitioning_np
    check_and_tag_outfile("--partitioning")

    #if np is int, this is the number of cpus

    #if np is list of node ids, the cpu 0 should take all indices from
    #0 to np[0], cpu 1 all indices from np[0] to np[1], ... and cpu[n]
    #all nodes from np[n-1] to the maximum index.
    #
    #The np list is therefore a list of indices that indicate where the
    #next cpu starts.
    #
    np_int = None
    np_list = None

    try:
        np_int = int( np )
    except ValueError:
        #could be that np is list
        np_list = eval(np)
        if type(np_list) != types.ListType:
            raise ValueError,\
                  "partitioning argument should be int or list of ints but is '%s'" % np
    if np_int:
        logging.info("Writinging vtk file showing partitioning %d cpus to '%s'."\
                     % (np_int,outfile))
        np_data = np_int
    else:
        assert np_list,"Internal Error"
        logging.info("Writing vtk file showing partitioning for %s to '%s'."\
                     % (np_list,outfile))
        np_data = np_list

    
    do_partitioning_np(mesh,np_data,outfile)

if outfile_feature == None and outfile!=None:
    logging.warn("Outfile name provided but not used ('%s')" % outfile)

